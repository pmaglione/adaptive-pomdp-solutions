# This file is a POMDP policy, represented as a set of "lower bound
# planes", each of which consists of an alpha vector and a corresponding
# action.  Given a particular belief b, this information can be used to
# answer two queries of interest:
#
#   1. What is a lower bound on the expected long-term reward starting
#        from belief b?
#   2. What is an action that achieves that expected reward lower bound?
#
# Each lower bound plane is only defined over a subset of the belief
# simplex--it is defined for those beliefs b such that the non-zero
# entries of b are a subset of the entries present in the plane's alpha
# vector.  If this condition holds we say the plane is 'applicable' to b.
#
# Given a belief b, both of the queries above can be answered by the
# following process: first, throw out all the planes that are not
# applicable to b.  Then, for each of the remaining planes, take the inner
# product of the plane's alpha vector with b.  The highest inner product
# value is the expected long-term reward lower bound, and the action label
# for that plane is the action that achieves the bound.

{
  policyType => "MaxPlanesLowerBound",
  numPlanes => 13,
  planes => [
    {
      action => 1,
      numEntries => 15,
      entries => [
        0, 0,
        1, 0,
        2, 0,
        3, 0,
        4, 0,
        5, 0,
        6, 0,
        7, 0,
        9, -10,
        10, -10,
        11, -10,
        12, -10,
        13, -10,
        14, -10,
        15, -10
      ]
    },
    {
      action => 2,
      numEntries => 17,
      entries => [
        0, -500,
        1, -500,
        2, -500,
        3, -500,
        4, -500,
        5, -500,
        6, -500,
        7, -500,
        8, 0,
        9, 0,
        10, 0,
        11, 0,
        12, 0,
        13, 0,
        14, 0,
        15, 0,
        16, 0
      ]
    },
    {
      action => 0,
      numEntries => 14,
      entries => [
        1, -39.6908,
        2, -78.4228,
        3, -118.889,
        4, -161.404,
        5, -205.901,
        6, -251.936,
        7, -283.087,
        9, -1.36487,
        10, -1.96445,
        11, -2.73674,
        12, -3.62734,
        13, -4.58944,
        14, -5.58382,
        15, -6.24874
      ]
    },
    {
      action => 0,
      numEntries => 14,
      entries => [
        1, -3.97651,
        2, -12.7622,
        3, -27.7474,
        4, -49.4164,
        5, -78.2053,
        6, -114.36,
        7, -142.53,
        9, -3.0123,
        10, -4.16946,
        11, -5.37053,
        12, -6.53858,
        13, -7.61774,
        14, -8.57034,
        15, -9.12356
      ]
    },
    {
      action => 0,
      numEntries => 14,
      entries => [
        1, -3.88693,
        2, -12.3977,
        3, -26.5324,
        4, -46.291,
        5, -71.6734,
        6, -102.68,
        7, -126.475,
        9, -3.36844,
        10, -4.62451,
        11, -5.7681,
        12, -6.79921,
        13, -7.71784,
        14, -8.524,
        15, -8.99895
      ]
    },
    {
      action => 0,
      numEntries => 14,
      entries => [
        1, -1.29149,
        2, -2.85947,
        3, -6.9692,
        4, -14.8859,
        5, -27.8748,
        6, -47.2012,
        7, -64.2312,
        9, -4.86542,
        10, -6.43029,
        11, -7.7196,
        12, -8.75867,
        13, -9.57279,
        14, -10.1873,
        15, -10.4985
      ]
    },
    {
      action => 0,
      numEntries => 14,
      entries => [
        1, -1.29821,
        2, -2.91415,
        3, -7.24255,
        4, -15.8234,
        5, -30.324,
        6, -52.4567,
        7, -72.2576,
        9, -4.53603,
        10, -6.04354,
        11, -7.41152,
        12, -8.57625,
        13, -9.51023,
        14, -10.2128,
        15, -10.5608
      ]
    },
    {
      action => 2,
      numEntries => 15,
      entries => [
        1, -500,
        2, -500,
        3, -500,
        4, -500,
        5, -500,
        6, -500,
        7, -500,
        8, 0,
        9, 0,
        10, 0,
        11, 0,
        12, 0,
        13, 0,
        14, 0,
        15, 0
      ]
    },
    {
      action => 0,
      numEntries => 15,
      entries => [
        1, -38.4963,
        2, -75.9925,
        3, -113.489,
        4, -150.985,
        5, -188.481,
        6, -225.977,
        7, -250.975,
        8, -1,
        9, -1.74992,
        10, -2.49985,
        11, -3.24978,
        12, -3.9997,
        13, -4.74962,
        14, -5.49955,
        15, -5.9995
      ]
    },
    {
      action => 0,
      numEntries => 15,
      entries => [
        1, -3.88693,
        2, -12.3977,
        3, -26.5324,
        4, -46.291,
        5, -71.6734,
        6, -102.68,
        7, -126.475,
        8, -1.9999,
        9, -3.36844,
        10, -4.62451,
        11, -5.7681,
        12, -6.79921,
        13, -7.71784,
        14, -8.524,
        15, -8.99895
      ]
    },
    {
      action => 0,
      numEntries => 15,
      entries => [
        1, -1.29149,
        2, -2.85947,
        3, -6.9692,
        4, -14.8859,
        5, -27.8748,
        6, -47.2012,
        7, -64.2312,
        8, -2.9997,
        9, -4.86542,
        10, -6.43029,
        11, -7.7196,
        12, -8.75867,
        13, -9.57279,
        14, -10.1873,
        15, -10.4985
      ]
    },
    {
      action => 0,
      numEntries => 15,
      entries => [
        1, -1.09685,
        2, -1.42888,
        3, -2.56791,
        4, -5.46532,
        5, -11.452,
        6, -22.2384,
        7, -33.1124,
        8, -3.9994,
        9, -6.24999,
        10, -7.96505,
        11, -9.23187,
        12, -10.1302,
        13, -10.732,
        14, -11.102,
        15, -11.2482
      ]
    },
    {
      action => 1,
      numEntries => 17,
      entries => [
        0, 0,
        1, 0,
        2, 0,
        3, 0,
        4, 0,
        5, 0,
        6, 0,
        7, 0,
        8, -10,
        9, -10,
        10, -10,
        11, -10,
        12, -10,
        13, -10,
        14, -10,
        15, -10,
        16, 0
      ]
    }
  ]
}
