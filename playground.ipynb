{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments on Dai's Framework\n",
    "\n",
    "In this notebook we study a set of extensions to a basic stopping algorithm by Dai et al.\n",
    "We analyse the performance and quality according to a set of metrics defined below and we compare with the basic Dai's algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pomdp_extensions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics: \n",
    " - **Classification cost** Each vote has a cost (assumed to be 1), and we compute the total cost for classifying all items\n",
    " - **Weighted classificaiton error = (fpc * FP + fnc * FN + ucc*UC)/N** FP= false positives, FB = false negatives, UC= items left unclassified, N= total number of items on which we reached a decision (or a decision to leave them unclassified), fpc= false positive cost, fnc = false negative cost, ucc=unclassified cost. Notice that loss here is INDEPENDENT of the cost\n",
    " - **Precision and Recall, F1, Fbeta**\n",
    " \n",
    "## Baselines\n",
    "- We compare with other baselines, which are:\n",
    " - fixed number of votes\n",
    " - two and break the tie\n",
    " - stop after S consecutive same votes\n",
    " - stop when difference among two classes greater than X\n",
    " \n",
    "\n",
    "## Extensions to Dai's framework:\n",
    "We consider the following extensions\n",
    "\n",
    "- Varying the cost for giving the wrong answer (this means varying fpc and fnc)\n",
    "- Dai divides the continuous space of (difficulty, true label) in (11*2)+1 discrete classes, we explore what happens as we reduce or increase this number\n",
    "- We add one more action, which is leave the items unclassified.\n",
    "- We experiment in sceanrios with varying error rates distribution for the workers\n",
    "- We use workers confusion matrix for error rates as opposed to \"plain\" error rates that are independent of the true label\n",
    "- we explore the above over a variety of real and simulated datasets\n",
    "- We experiment with balanced and unbalanced datasets\n",
    "- We experiment with adding a prior based on an estimation of the dataset balance\n",
    "- (Future: see what changes for multi predicate)\n",
    "- **Estimate after ('after' in plots) means that workers error rate $\\gamma$ estimation using EM starts after submitting the first answer, otherwise we try estimating $\\gamma$ after collecting 2 votes over an item** We compare with Dai's who i) they take one vote per item at each iteration, ii) they re-estimate error rates ONLY after doing the transitions. We want to see what happens if we do that before.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Try POMDP models with different rewards\n",
    "\n",
    "In this set of experiments we consider how POMDP performs with respect to the baselines, on our set of test datasets, and we vary the two parameters, **fnc** and **fpc**.\n",
    "\n",
    "Also, for all experiments, we test the difference between conputing error rates (running EM) before or after updating the POMDP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment settings\n",
    "### POMDP definition: \n",
    " - States: 23\n",
    " - Actions: 3 = {RequestVote, SubmitFalse, SubmitTrue}\n",
    " \n",
    " Transitions: \n",
    " - $T(S_i, Action=RequestVote, S_i) = 1$\n",
    " - $T(S_i, Action=SubmitTrue, S_{terminal}) = 1$\n",
    " - $T(S_i, Action=SubmitFalse, S_{terminal}) = 1$\n",
    " \n",
    " Observations probabilities:\n",
    " - $O(S_i, RequestVote, CorrectAnswer) = Acc$\n",
    " - $O(S_i, RequestVote, IncorrectAnswer) = 1 - Acc$\n",
    " \n",
    " Worker Accuracy Formula:\n",
    " - $Acc(d, \\gamma) = \\frac{1}{2} (1 + (1 - d)^{\\gamma}) $\n",
    " \n",
    " Rewards:\n",
    " - Request vote: -1\n",
    " - Correct answer: 0\n",
    " - Beta = fnc/fpc \n",
    " \n",
    " \n",
    "\n",
    "Workers:\n",
    " - Binary classification\n",
    " - 1000 items\n",
    " - average number of votes per worker: (5, 10, 20)\n",
    " - Error rate distribution: $\\gamma \\sim Normal(1, 0.2)$\n",
    " - Accuracy Â±75%\n",
    " \n",
    "Variations of the experiment:\n",
    " - fpc = fnc = {-1, -10, -20, -50, -500, -1000}\n",
    " - same for fpc, but we make fnc = fpc * 10, and fnc = fpc * 100\n",
    " - as the error rate distribution varies\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_num = 1000\n",
    "positive_percentage = 0.5\n",
    "item_difficulty = 0.5\n",
    "workers_num = 100\n",
    "avg_workers_error_rate = 1\n",
    "dist_name = \"Normal\" # possible values: Normal, Beta\n",
    "dist_mean = 1\n",
    "dist_std = 0.2\n",
    "states_num = 23\n",
    "fncs = [-1, -5, -10, -500]\n",
    "fpcs = [-1, -5, -10, -500]\n",
    "moment_error_estimations = [False, True]\n",
    "\n",
    "policy_path = \"/Users/pmaglione/Repos/adaptive-pomdp-solutions/dai_pomdp/ModelLearning/Policies/\"\n",
    "output_file = \"/Users/pmaglione/Repos/adaptive-pomdp-solutions/results/base.csv\"\n",
    "\n",
    "def get_policy_name(items_num, fnc, fpc):\n",
    "    return f'wrong-cost-fnc{fnc}-fpc{fpc}.policy'\n",
    "\n",
    "columns_to_print = ['cost', 'fbeta']\n",
    "\n",
    "run_base_case(items_num, positive_percentage, item_difficulty, workers_num, avg_workers_error_rate,\n",
    "                  dist_name, dist_mean, dist_std, states_num, policy_path, output_file, moment_error_estimations,\n",
    "                  fncs, fpcs, get_policy_name, columns_to_print)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test with different number of states in the model of MDP\n",
    "\n",
    "POMDP definition: \n",
    " - States #: {5,9,13,17}\n",
    "     (difficulty, true_label)\n",
    "    - 5:  (0,0)(1,0)(0,1)(1,1)(T)\n",
    "    - 9:  (0,0)(0.33,0)(0.66,0)(1,0)(0,1)(0.33,1)(0.66,1)(1,1)(T)\n",
    "    - 13: (0,0)(0.2,0)(0.4,0)(0.6,0)(0.8,0)(1,0)(0,1)(0.2,1)(0.4,1)(0.6,1)(0.8,1)(1,1)(T)\n",
    "    - 17: (0,0)(0.15,0)(0.3,0)(0.45,0)(0.6,0)(0.75,0)(0.9,0)(1,0)(0,1)(0.15,1)(0.3,1)(0.45,1)(0.6,1)(0.75,1)(0.9,1)(1,1)(T)\n",
    "    \n",
    "    \n",
    " - Actions: 4 = {RequestVote, SubmitFalse, SubmitTrue}\n",
    " \n",
    " Transitions: \n",
    " - $T(S_i, Action=RequestVote, S_i) = 1$\n",
    " - $T(S_i, Action=SubmitTrue, S_{terminal}) = 1$\n",
    " - $T(S_i, Action=SubmitFalse, S_{terminal}) = 1$\n",
    " \n",
    " Observations probabilities:\n",
    " - $O(S_i, RequestVote, CorrectAnswer) = Acc$\n",
    " - $O(S_i, RequestVote, IncorrectAnswer) = 1 - Acc$\n",
    " \n",
    " Worker Accuracy Formula:\n",
    " - $Acc(d, \\gamma) = \\frac{1}{2} (1 + (1 - d)^{\\gamma}) $\n",
    " \n",
    " Rewards:\n",
    " - Request vote: -1\n",
    " - Correct answer: 0\n",
    " - Wrong answer: -500\n",
    "\n",
    "Workers:\n",
    " - Amount: 100\n",
    " - Error rate distribution: $\\gamma \\sim Normal(1, 0.2)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_num = 1000\n",
    "positive_percentage = 0.5\n",
    "item_difficulty = 0.5\n",
    "workers_num = 100\n",
    "avg_workers_error_rate = 1\n",
    "dist_name = \"Normal\" # possible values: Normal, Beta\n",
    "dist_mean = 1\n",
    "dist_std = 0.2\n",
    "states_num = 23\n",
    "fncs = [-1, -5, -10, -500]\n",
    "fpcs = [-1, -5, -10, -500]\n",
    "fncs = [-1, -5]\n",
    "fpcs = [-1, -5]\n",
    "moment_error_estimations = [False, True]\n",
    "\n",
    "states_nums = [5,9,13,17,43,203]\n",
    "states_nums = [5,9]\n",
    "states_diffs = [[0,1], #5 states\n",
    "         [0, 0.33, 0.66, 1], #9 states\n",
    "         [0, 0.2, 0.4, 0.6, 0.8, 1], # 13 states\n",
    "         [0, 0.15, 0.3, 0.45, 0.6, 0.75, 0.9, 1], #17 states\n",
    "         np.arange(0, 1.05, .05), #43\n",
    "         np.arange(0, 1.01, .01) # 203\n",
    "        ]\n",
    "\n",
    "policy_path = \"/Users/pmaglione/Repos/adaptive-pomdp-solutions/dai_pomdp/ModelLearning/Policies/\"\n",
    "output_file = \"/Users/pmaglione/Repos/adaptive-pomdp-solutions/results/num_states.csv\"\n",
    "\n",
    "columns_to_print = ['cost', 'fbeta']\n",
    "\n",
    "def get_policy_name(states_num, fnc, fpc):\n",
    "    return f'vc-{states_num}states-fnc{fnc}-fpc{fpc}.policy'\n",
    "\n",
    "run_vary_num_states(items_num, positive_percentage, item_difficulty, workers_num, avg_workers_error_rate,\n",
    "                  dist_name, dist_mean, dist_std, states_nums, states_diffs, policy_path, output_file,\n",
    "                moment_error_estimations, fncs, fpcs, get_policy_name, columns_to_print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
